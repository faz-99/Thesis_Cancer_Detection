{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACH Dataset - Exploratory Data Analysis\n",
    "\n",
    "This notebook provides a comprehensive analysis of the BACH (Breast Cancer Histology) dataset.\n",
    "\n",
    "## Dataset Overview\n",
    "- **BACH**: Breast Cancer Histology Challenge dataset\n",
    "- **Classes**: 4 (Normal, Benign, In Situ Carcinoma, Invasive Carcinoma)\n",
    "- **Resolution**: High-resolution (2048 x 1536 pixels)\n",
    "- **Total Images**: 400 (100 per class)\n",
    "- **Source**: ICIAR 2018 Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from bach_data_utils import create_bach_metadata\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Constants\n",
    "BACH_ROOT = '../data/bach'\n",
    "FIGSIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup\n",
    "\n",
    "First, let's check if BACH data is available and download if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if BACH data exists\n",
    "if not os.path.exists(BACH_ROOT):\n",
    "    print(\"BACH dataset not found. Please download it first.\")\n",
    "    print(\"\\nDownload options:\")\n",
    "    print(\"1. Official: https://iciar2018-challenge.grand-challenge.org/Dataset/\")\n",
    "    print(\"2. Kaggle: https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images\")\n",
    "    print(\"\\nExpected structure:\")\n",
    "    print(\"data/bach/\")\n",
    "    print(\"├── Normal/\")\n",
    "    print(\"├── Benign/\")\n",
    "    print(\"├── InSitu/\")\n",
    "    print(\"└── Invasive/\")\n",
    "else:\n",
    "    print(f\"BACH dataset found at: {BACH_ROOT}\")\n",
    "    \n",
    "    # List directory structure\n",
    "    for root, dirs, files in os.walk(BACH_ROOT):\n",
    "        level = root.replace(BACH_ROOT, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:3]:  # Show first 3 files\n",
    "            print(f\"{subindent}{file}\")\n",
    "        if len(files) > 3:\n",
    "            print(f\"{subindent}... and {len(files)-3} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Loading and Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BACH metadata\n",
    "if os.path.exists(BACH_ROOT):\n",
    "    bach_df = create_bach_metadata(BACH_ROOT)\n",
    "    print(f\"Total images: {len(bach_df)}\")\n",
    "    print(f\"\\nDataset info:\")\n",
    "    print(bach_df.info())\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    display(bach_df.head())\n",
    "else:\n",
    "    print(\"Please download BACH dataset first to proceed with EDA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(BACH_ROOT):\n",
    "    # Class distribution\n",
    "    class_counts = bach_df['class'].value_counts()\n",
    "    print(\"Class Distribution:\")\n",
    "    print(class_counts)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Bar plot\n",
    "    class_counts.plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "    axes[0].set_title('BACH Dataset - Class Distribution')\n",
    "    axes[0].set_xlabel('Class')\n",
    "    axes[0].set_ylabel('Number of Images')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[1].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('BACH Dataset - Class Proportions')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Class balance analysis\n",
    "    print(f\"\\nClass Balance Analysis:\")\n",
    "    print(f\"Most common class: {class_counts.index[0]} ({class_counts.iloc[0]} images)\")\n",
    "    print(f\"Least common class: {class_counts.index[-1]} ({class_counts.iloc[-1]} images)\")\n",
    "    print(f\"Imbalance ratio: {class_counts.iloc[0] / class_counts.iloc[-1]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Properties Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(BACH_ROOT):\n",
    "    # Analyze image properties\n",
    "    def analyze_image_properties(df, sample_size=50):\n",
    "        \"\"\"Analyze image dimensions, file sizes, and formats\"\"\"\n",
    "        properties = []\n",
    "        \n",
    "        # Sample images for analysis\n",
    "        sample_df = df.sample(min(sample_size, len(df)), random_state=42)\n",
    "        \n",
    "        for _, row in sample_df.iterrows():\n",
    "            try:\n",
    "                img_path = row['path']\n",
    "                img = Image.open(img_path)\n",
    "                \n",
    "                properties.append({\n",
    "                    'class': row['class'],\n",
    "                    'width': img.width,\n",
    "                    'height': img.height,\n",
    "                    'aspect_ratio': img.width / img.height,\n",
    "                    'file_size_mb': os.path.getsize(img_path) / (1024 * 1024),\n",
    "                    'format': img.format,\n",
    "                    'mode': img.mode\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "        \n",
    "        return pd.DataFrame(properties)\n",
    "    \n",
    "    # Analyze properties\n",
    "    props_df = analyze_image_properties(bach_df)\n",
    "    \n",
    "    print(\"Image Properties Summary:\")\n",
    "    print(props_df.describe())\n",
    "    \n",
    "    # Visualize dimensions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Width distribution\n",
    "    props_df['width'].hist(bins=20, ax=axes[0,0], alpha=0.7)\n",
    "    axes[0,0].set_title('Image Width Distribution')\n",
    "    axes[0,0].set_xlabel('Width (pixels)')\n",
    "    \n",
    "    # Height distribution\n",
    "    props_df['height'].hist(bins=20, ax=axes[0,1], alpha=0.7)\n",
    "    axes[0,1].set_title('Image Height Distribution')\n",
    "    axes[0,1].set_xlabel('Height (pixels)')\n",
    "    \n",
    "    # Aspect ratio by class\n",
    "    sns.boxplot(data=props_df, x='class', y='aspect_ratio', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Aspect Ratio by Class')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # File size distribution\n",
    "    props_df['file_size_mb'].hist(bins=20, ax=axes[1,1], alpha=0.7)\n",
    "    axes[1,1].set_title('File Size Distribution')\n",
    "    axes[1,1].set_xlabel('File Size (MB)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Format and mode analysis\n",
    "    print(f\"\\nImage Formats: {props_df['format'].value_counts().to_dict()}\")\n",
    "    print(f\"Color Modes: {props_df['mode'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Images Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(BACH_ROOT):\n",
    "    def display_sample_images(df, samples_per_class=2, figsize=(16, 12)):\n",
    "        \"\"\"Display sample images from each class\"\"\"\n",
    "        classes = df['class'].unique()\n",
    "        n_classes = len(classes)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_classes, samples_per_class, figsize=figsize)\n",
    "        if n_classes == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, class_name in enumerate(classes):\n",
    "            class_df = df[df['class'] == class_name]\n",
    "            samples = class_df.sample(min(samples_per_class, len(class_df)), random_state=42)\n",
    "            \n",
    "            for j, (_, row) in enumerate(samples.iterrows()):\n",
    "                if j >= samples_per_class:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    img = Image.open(row['path'])\n",
    "                    # Resize for display\n",
    "                    img_resized = img.resize((400, 300), Image.Resampling.LANCZOS)\n",
    "                    \n",
    "                    axes[i, j].imshow(img_resized)\n",
    "                    axes[i, j].set_title(f\"{class_name}\\n{os.path.basename(row['path'])}\")\n",
    "                    axes[i, j].axis('off')\n",
    "                except Exception as e:\n",
    "                    axes[i, j].text(0.5, 0.5, f'Error loading\\n{e}', \n",
    "                                  ha='center', va='center', transform=axes[i, j].transAxes)\n",
    "                    axes[i, j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"Sample Images from Each Class:\")\n",
    "    display_sample_images(bach_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(BACH_ROOT):\n",
    "    def analyze_color_properties(df, sample_size=20):\n",
    "        \"\"\"Analyze color properties of images\"\"\"\n",
    "        color_stats = []\n",
    "        \n",
    "        # Sample images for analysis\n",
    "        sample_df = df.groupby('class').apply(\n",
    "            lambda x: x.sample(min(sample_size//len(df['class'].unique()), len(x)), random_state=42)\n",
    "        ).reset_index(drop=True)\n",
    "        \n",
    "        for _, row in sample_df.iterrows():\n",
    "            try:\n",
    "                img = Image.open(row['path']).convert('RGB')\n",
    "                # Resize for faster processing\n",
    "                img_small = img.resize((224, 224), Image.Resampling.LANCZOS)\n",
    "                img_array = np.array(img_small)\n",
    "                \n",
    "                # Calculate color statistics\n",
    "                color_stats.append({\n",
    "                    'class': row['class'],\n",
    "                    'mean_r': np.mean(img_array[:,:,0]),\n",
    "                    'mean_g': np.mean(img_array[:,:,1]),\n",
    "                    'mean_b': np.mean(img_array[:,:,2]),\n",
    "                    'std_r': np.std(img_array[:,:,0]),\n",
    "                    'std_g': np.std(img_array[:,:,1]),\n",
    "                    'std_b': np.std(img_array[:,:,2]),\n",
    "                    'brightness': np.mean(img_array),\n",
    "                    'contrast': np.std(img_array)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {row['path']}: {e}\")\n",
    "        \n",
    "        return pd.DataFrame(color_stats)\n",
    "    \n",
    "    # Analyze colors\n",
    "    color_df = analyze_color_properties(bach_df)\n",
    "    \n",
    "    if not color_df.empty:\n",
    "        # Visualize color properties\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # RGB means by class\n",
    "        rgb_means = color_df.groupby('class')[['mean_r', 'mean_g', 'mean_b']].mean()\n",
    "        rgb_means.plot(kind='bar', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Average RGB Values by Class')\n",
    "        axes[0,0].set_ylabel('Mean Pixel Value')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        axes[0,0].legend(['Red', 'Green', 'Blue'])\n",
    "        \n",
    "        # Brightness distribution\n",
    "        sns.boxplot(data=color_df, x='class', y='brightness', ax=axes[0,1])\n",
    "        axes[0,1].set_title('Brightness Distribution by Class')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Contrast distribution\n",
    "        sns.boxplot(data=color_df, x='class', y='contrast', ax=axes[1,0])\n",
    "        axes[1,0].set_title('Contrast Distribution by Class')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Color variance\n",
    "        color_variance = color_df.groupby('class')[['std_r', 'std_g', 'std_b']].mean()\n",
    "        color_variance.plot(kind='bar', ax=axes[1,1])\n",
    "        axes[1,1].set_title('Color Variance by Class')\n",
    "        axes[1,1].set_ylabel('Standard Deviation')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        axes[1,1].legend(['Red Std', 'Green Std', 'Blue Std'])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\nColor Statistics Summary:\")\n",
    "        print(color_df.groupby('class')[['brightness', 'contrast']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Texture Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(BACH_ROOT):\n",
    "    def analyze_texture_features(df, sample_size=10):\n",
    "        \"\"\"Analyze texture features using basic image processing\"\"\"\n",
    "        texture_stats = []\n",
    "        \n",
    "        # Sample images for analysis\n",
    "        sample_df = df.groupby('class').apply(\n",
    "            lambda x: x.sample(min(sample_size//len(df['class'].unique()), len(x)), random_state=42)\n",
    "        ).reset_index(drop=True)\n",
    "        \n",
    "        for _, row in sample_df.iterrows():\n",
    "            try:\n",
    "                img = cv2.imread(row['path'])\n",
    "                if img is None:\n",
    "                    continue\n",
    "                    \n",
    "                # Convert to grayscale\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                # Resize for faster processing\n",
    "                gray = cv2.resize(gray, (224, 224))\n",
    "                \n",
    "                # Calculate texture features\n",
    "                # Laplacian variance (measure of focus/sharpness)\n",
    "                laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "                \n",
    "                # Sobel gradients (edge information)\n",
    "                sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "                sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "                sobel_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "                \n",
    "                texture_stats.append({\n",
    "                    'class': row['class'],\n",
    "                    'laplacian_variance': laplacian_var,\n",
    "                    'sobel_mean': np.mean(sobel_magnitude),\n",
    "                    'sobel_std': np.std(sobel_magnitude),\n",
    "                    'intensity_std': np.std(gray),\n",
    "                    'intensity_range': np.ptp(gray)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {row['path']}: {e}\")\n",
    "        \n",
    "        return pd.DataFrame(texture_stats)\n",
    "    \n",
    "    # Analyze texture\n",
    "    texture_df = analyze_texture_features(bach_df)\n",
    "    \n",
    "    if not texture_df.empty:\n",
    "        # Visualize texture properties\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Laplacian variance (sharpness)\n",
    "        sns.boxplot(data=texture_df, x='class', y='laplacian_variance', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Image Sharpness (Laplacian Variance)')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Edge strength\n",
    "        sns.boxplot(data=texture_df, x='class', y='sobel_mean', ax=axes[0,1])\n",
    "        axes[0,1].set_title('Edge Strength (Sobel Mean)')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Intensity variation\n",
    "        sns.boxplot(data=texture_df, x='class', y='intensity_std', ax=axes[1,0])\n",
    "        axes[1,0].set_title('Intensity Variation')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Intensity range\n",
    "        sns.boxplot(data=texture_df, x='class', y='intensity_range', ax=axes[1,1])\n",
    "        axes[1,1].set_title('Intensity Range')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\nTexture Statistics Summary:\")\n",
    "        print(texture_df.groupby('class').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(BACH_ROOT):\n",
    "    def assess_data_quality(df):\n",
    "        \"\"\"Assess data quality issues\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        print(\"Data Quality Assessment:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Check for missing files\n",
    "        missing_files = 0\n",
    "        corrupted_files = 0\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            img_path = row['path']\n",
    "            \n",
    "            # Check if file exists\n",
    "            if not os.path.exists(img_path):\n",
    "                missing_files += 1\n",
    "                issues.append(f\"Missing file: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Check if file can be opened\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                img.verify()  # Verify image integrity\n",
    "            except Exception as e:\n",
    "                corrupted_files += 1\n",
    "                issues.append(f\"Corrupted file: {img_path} - {e}\")\n",
    "        \n",
    "        print(f\"Total images: {len(df)}\")\n",
    "        print(f\"Missing files: {missing_files}\")\n",
    "        print(f\"Corrupted files: {corrupted_files}\")\n",
    "        print(f\"Valid images: {len(df) - missing_files - corrupted_files}\")\n",
    "        \n",
    "        # Check class balance\n",
    "        class_counts = df['class'].value_counts()\n",
    "        min_class_size = class_counts.min()\n",
    "        max_class_size = class_counts.max()\n",
    "        imbalance_ratio = max_class_size / min_class_size\n",
    "        \n",
    "        print(f\"\\nClass Balance:\")\n",
    "        print(f\"Most common class: {max_class_size} images\")\n",
    "        print(f\"Least common class: {min_class_size} images\")\n",
    "        print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "        \n",
    "        if imbalance_ratio > 2.0:\n",
    "            issues.append(f\"Significant class imbalance detected: {imbalance_ratio:.2f}:1\")\n",
    "        \n",
    "        # Check for duplicate filenames\n",
    "        duplicate_names = df['filename'].duplicated().sum()\n",
    "        if duplicate_names > 0:\n",
    "            issues.append(f\"Found {duplicate_names} duplicate filenames\")\n",
    "        \n",
    "        print(f\"\\nData Quality Issues Found: {len(issues)}\")\n",
    "        for issue in issues[:10]:  # Show first 10 issues\n",
    "            print(f\"- {issue}\")\n",
    "        \n",
    "        if len(issues) > 10:\n",
    "            print(f\"... and {len(issues) - 10} more issues\")\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    # Assess data quality\n",
    "    quality_issues = assess_data_quality(bach_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison with BreakHis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(BACH_ROOT):\n",
    "    # Load BreakHis for comparison\n",
    "    sys.path.append('../src')\n",
    "    from data_utils import create_metadata\n",
    "    \n",
    "    breakhis_root = '../data/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast'\n",
    "    \n",
    "    if os.path.exists(breakhis_root):\n",
    "        breakhis_df = create_metadata(breakhis_root)\n",
    "        \n",
    "        print(\"Dataset Comparison: BACH vs BreakHis\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        comparison_data = {\n",
    "            'Metric': ['Total Images', 'Number of Classes', 'Avg Images per Class', \n",
    "                      'Min Class Size', 'Max Class Size', 'Imbalance Ratio'],\n",
    "            'BACH': [\n",
    "                len(bach_df),\n",
    "                bach_df['class'].nunique(),\n",
    "                len(bach_df) / bach_df['class'].nunique(),\n",
    "                bach_df['class'].value_counts().min(),\n",
    "                bach_df['class'].value_counts().max(),\n",
    "                bach_df['class'].value_counts().max() / bach_df['class'].value_counts().min()\n",
    "            ],\n",
    "            'BreakHis': [\n",
    "                len(breakhis_df),\n",
    "                breakhis_df['subclass'].nunique(),\n",
    "                len(breakhis_df) / breakhis_df['subclass'].nunique(),\n",
    "                breakhis_df['subclass'].value_counts().min(),\n",
    "                breakhis_df['subclass'].value_counts().max(),\n",
    "                breakhis_df['subclass'].value_counts().max() / breakhis_df['subclass'].value_counts().min()\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        \n",
    "        # Visualize comparison\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Dataset sizes\n",
    "        datasets = ['BACH', 'BreakHis']\n",
    "        sizes = [len(bach_df), len(breakhis_df)]\n",
    "        axes[0].bar(datasets, sizes, color=['skyblue', 'lightcoral'])\n",
    "        axes[0].set_title('Dataset Sizes Comparison')\n",
    "        axes[0].set_ylabel('Number of Images')\n",
    "        \n",
    "        # Number of classes\n",
    "        classes = [bach_df['class'].nunique(), breakhis_df['subclass'].nunique()]\n",
    "        axes[1].bar(datasets, classes, color=['lightgreen', 'orange'])\n",
    "        axes[1].set_title('Number of Classes Comparison')\n",
    "        axes[1].set_ylabel('Number of Classes')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"BreakHis dataset not found for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recommendations for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(BACH_ROOT):\n",
    "    print(\"BACH Dataset - Training Recommendations\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Dataset characteristics\n",
    "    total_images = len(bach_df)\n",
    "    n_classes = bach_df['class'].nunique()\n",
    "    class_counts = bach_df['class'].value_counts()\n",
    "    imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "    \n",
    "    print(f\"Dataset Size: {total_images} images\")\n",
    "    print(f\"Number of Classes: {n_classes}\")\n",
    "    print(f\"Class Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "    \n",
    "    print(\"\\nRecommendations:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Data augmentation\n",
    "    if total_images < 1000:\n",
    "        print(\"✓ Use aggressive data augmentation (rotation, flipping, color jittering)\")\n",
    "        print(\"✓ Consider GAN-based augmentation for synthetic data generation\")\n",
    "    \n",
    "    # Class imbalance\n",
    "    if imbalance_ratio > 1.5:\n",
    "        print(\"✓ Use weighted sampling or class weights to handle imbalance\")\n",
    "        print(\"✓ Consider focal loss for better handling of hard examples\")\n",
    "    \n",
    "    # Model architecture\n",
    "    print(\"✓ Use transfer learning with ImageNet pretrained models\")\n",
    "    print(\"✓ EfficientNet or ResNet architectures recommended for histopathology\")\n",
    "    \n",
    "    # Training strategy\n",
    "    print(\"✓ Use stratified splits to maintain class distribution\")\n",
    "    print(\"✓ Implement early stopping and learning rate scheduling\")\n",
    "    print(\"✓ Use cross-validation for robust performance estimation\")\n",
    "    \n",
    "    # High-resolution considerations\n",
    "    print(\"✓ BACH images are high-resolution - consider multi-scale training\")\n",
    "    print(\"✓ Use progressive resizing: start with smaller images, increase size\")\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"✓ Use multiple metrics: Accuracy, F1-score, AUC-ROC\")\n",
    "    print(\"✓ Analyze per-class performance and confusion matrices\")\n",
    "    \n",
    "    # Combined training\n",
    "    if os.path.exists('../data/breakhis'):\n",
    "        print(\"\\n✓ Consider combining with BreakHis dataset for improved generalization\")\n",
    "        print(\"✓ Use domain adaptation techniques for multi-dataset training\")\n",
    "    \n",
    "    print(\"\\nSuggested Train/Val/Test Split:\")\n",
    "    print(f\"- Training: {int(total_images * 0.7)} images (70%)\")\n",
    "    print(f\"- Validation: {int(total_images * 0.15)} images (15%)\")\n",
    "    print(f\"- Testing: {int(total_images * 0.15)} images (15%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This EDA provides a comprehensive analysis of the BACH dataset including:\n",
    "\n",
    "1. **Dataset Overview**: Class distribution and basic statistics\n",
    "2. **Image Properties**: Dimensions, file sizes, and formats\n",
    "3. **Visual Analysis**: Sample images from each class\n",
    "4. **Color Analysis**: RGB statistics and brightness/contrast patterns\n",
    "5. **Texture Analysis**: Edge strength and intensity variations\n",
    "6. **Data Quality**: Assessment of missing or corrupted files\n",
    "7. **Comparison**: Side-by-side analysis with BreakHis dataset\n",
    "8. **Recommendations**: Specific suggestions for model training\n",
    "\n",
    "The BACH dataset provides high-quality histopathology images that complement the BreakHis dataset well for comprehensive breast cancer detection research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}