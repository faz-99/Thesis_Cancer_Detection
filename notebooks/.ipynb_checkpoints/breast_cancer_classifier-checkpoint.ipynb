{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/ambarish/breakhis\n",
      "License(s): unknown\n",
      "Downloading breakhis.zip to ../data/breakhis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.99G/3.99G [00:04<00:00, 950MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['kaggle', 'datasets', 'download', '-d', 'ambarish/breakhis', '-p', '../data/breakhis', '--unzip'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Step 1: Set Kaggle API Key location\n",
    "kaggle_json_path = os.path.expanduser(\"~/.kaggle\")\n",
    "os.makedirs(kaggle_json_path, exist_ok=True)\n",
    "\n",
    "# NOTE: Adjust this if your kaggle.json is in the notebook folder\n",
    "local_kaggle_json = \"kaggle.json\"\n",
    "\n",
    "if not os.path.exists(local_kaggle_json):\n",
    "    raise FileNotFoundError(\"âš ï¸ kaggle.json not found in the notebook directory!\")\n",
    "\n",
    "# Move kaggle.json to ~/.kaggle and set permissions\n",
    "shutil.copy(local_kaggle_json, os.path.join(kaggle_json_path, \"kaggle.json\"))\n",
    "os.chmod(os.path.join(kaggle_json_path, \"kaggle.json\"), 0o600)\n",
    "\n",
    "# Step 2: Create data directory\n",
    "data_path = \"../data/breakhis\"  # Going one level up from notebooks/\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Step 3: Run Kaggle CLI to download and unzip\n",
    "subprocess.run([\n",
    "    \"kaggle\", \"datasets\", \"download\",\n",
    "    \"-d\", \"ambarish/breakhis\",\n",
    "    \"-p\", data_path,\n",
    "    \"--unzip\"\n",
    "], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 7909 .png files\n",
      "ðŸ“„ ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-009.png\n",
      "ðŸ“„ ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-008.png\n",
      "ðŸ“„ ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-003.png\n",
      "ðŸ“„ ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-002.png\n",
      "ðŸ“„ ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-13418DE/100X/SOB_M_MC-14-13418DE-100-014.png\n",
      "\n",
      "âœ… Sample entries:\n",
      "                                                path label_type  \\\n",
      "0  ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histo...  malignant   \n",
      "1  ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histo...  malignant   \n",
      "2  ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histo...  malignant   \n",
      "3  ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histo...  malignant   \n",
      "4  ../data/breakhis/BreaKHis_v1/BreaKHis_v1/histo...  malignant   \n",
      "\n",
      "             subclass magnification                         filename  \n",
      "0  mucinous_carcinoma          100X  SOB_M_MC-14-13418DE-100-009.png  \n",
      "1  mucinous_carcinoma          100X  SOB_M_MC-14-13418DE-100-008.png  \n",
      "2  mucinous_carcinoma          100X  SOB_M_MC-14-13418DE-100-003.png  \n",
      "3  mucinous_carcinoma          100X  SOB_M_MC-14-13418DE-100-002.png  \n",
      "4  mucinous_carcinoma          100X  SOB_M_MC-14-13418DE-100-014.png  \n",
      "\n",
      "ðŸ“Š Subclass distribution:\n",
      "subclass\n",
      "ductal_carcinoma       3451\n",
      "fibroadenoma           1014\n",
      "mucinous_carcinoma      792\n",
      "lobular_carcinoma       626\n",
      "tubular_adenoma         569\n",
      "papillary_carcinoma     560\n",
      "phyllodes_tumor         453\n",
      "adenosis                444\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ”¬ Magnification distribution:\n",
      "magnification\n",
      "100X    2081\n",
      "200X    2013\n",
      "40X     1995\n",
      "400X    1820\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ·ï¸ Label type distribution:\n",
      "label_type\n",
      "malignant    5429\n",
      "benign       2480\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Set dataset root path\n",
    "dataset_root = \"../data/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast\"\n",
    "\n",
    "# Sanity check\n",
    "if not os.path.exists(dataset_root):\n",
    "    raise FileNotFoundError(f\"âŒ Dataset path not found: {dataset_root}\")\n",
    "\n",
    "# Get all image paths (recursive across magnifications)\n",
    "image_paths = glob(os.path.join(dataset_root, \"*\", \"*\", \"*\", \"*\", \"*\", \"*.png\"))\n",
    "print(f\"ðŸ” Found {len(image_paths)} .png files\")\n",
    "\n",
    "\n",
    "# Parse image paths to extract metadata\n",
    "data = []\n",
    "\n",
    "for path in image_paths:\n",
    "    parts = path.split(os.sep)\n",
    "    try:\n",
    "        label_type = parts[-6]         # 'malignant' or 'benign'\n",
    "        subclass = parts[-4]           # e.g. 'mucinous_carcinoma'\n",
    "        magnification = parts[-2]      # e.g. '100X'\n",
    "        filename = os.path.basename(path)\n",
    "\n",
    "        data.append({\n",
    "            \"path\": path,\n",
    "            \"label_type\": label_type,\n",
    "            \"subclass\": subclass,\n",
    "            \"magnification\": magnification,\n",
    "            \"filename\": filename\n",
    "        })\n",
    "    except IndexError:\n",
    "        print(f\"â— Skipping malformed path: {path}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "metadata = pd.DataFrame(data)\n",
    "\n",
    "# Display basic metadata\n",
    "print(\"\\nâœ… Sample entries:\")\n",
    "print(metadata.head())\n",
    "\n",
    "print(\"\\nðŸ“Š Subclass distribution:\")\n",
    "print(metadata[\"subclass\"].value_counts())\n",
    "\n",
    "print(\"\\nðŸ”¬ Magnification distribution:\")\n",
    "print(metadata[\"magnification\"].value_counts())\n",
    "\n",
    "print(\"\\nðŸ·ï¸ Label type distribution:\")\n",
    "print(metadata[\"label_type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Documents/GitHub/Thesis_Cancer_Detection/notebooks/breast_cancer_classifier.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/Thesis_Cancer_Detection/notebooks/breast_cancer_classifier.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/Thesis_Cancer_Detection/notebooks/breast_cancer_classifier.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mseaborn\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/Thesis_Cancer_Detection/notebooks/breast_cancer_classifier.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Plot subclass distribution\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Documents/GitHub/Thesis_Cancer_Detection/notebooks/breast_cancer_classifier.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m5\u001b[39m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot subclass distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.countplot(data=metadata, x=\"subclass\", order=metadata[\"subclass\"].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Distribution of Subclasses\")\n",
    "plt.show()\n",
    "\n",
    "# Plot magnification distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=metadata, x=\"magnification\", order=metadata[\"magnification\"].value_counts().index)\n",
    "plt.title(\"Distribution of Magnifications\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract patient ID from filename\n",
    "def extract_patient_id(path):\n",
    "    filename = os.path.basename(path)\n",
    "    return filename.split(\"_\")[2]  # e.g., '14-12345'\n",
    "\n",
    "metadata[\"patient_id\"] = metadata[\"path\"].apply(extract_patient_id)\n",
    "\n",
    "# Drop duplicate patient entries to avoid leakage\n",
    "unique_patients = metadata[[\"patient_id\", \"subclass\"]].drop_duplicates()\n",
    "\n",
    "# Train/val/test patient-wise split\n",
    "train_ids, test_ids = train_test_split(\n",
    "    unique_patients,\n",
    "    test_size=0.15,\n",
    "    stratify=unique_patients[\"subclass\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    train_ids,\n",
    "    test_size=0.15 / 0.85,\n",
    "    stratify=train_ids[\"subclass\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Map back to full data\n",
    "train_df = metadata[metadata[\"patient_id\"].isin(train_ids[\"patient_id\"])]\n",
    "val_df = metadata[metadata[\"patient_id\"].isin(val_ids[\"patient_id\"])]\n",
    "test_df = metadata[metadata[\"patient_id\"].isin(test_ids[\"patient_id\"])]\n",
    "\n",
    "# Show class counts\n",
    "print(\"Train:\", train_df[\"subclass\"].value_counts())\n",
    "print(\"Val:\", val_df[\"subclass\"].value_counts())\n",
    "print(\"Test:\", test_df[\"subclass\"].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
