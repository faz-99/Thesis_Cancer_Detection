{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Exploratory Data Analysis (EDA)\n",
    "## Breast Cancer Detection using BreakHis Dataset\n",
    "\n",
    "This notebook provides a comprehensive analysis of the BreakHis dataset for breast cancer histopathological image classification.\n",
    "\n",
    "### Dataset Overview\n",
    "- **Dataset**: BreakHis (Breast Cancer Histopathological Database)\n",
    "- **Classes**: 8 total (4 benign + 4 malignant)\n",
    "- **Magnifications**: 40X, 100X, 200X, 400X\n",
    "- **Image Format**: PNG\n",
    "- **Total Images**: ~7,900\n",
    "\n",
    "### Analysis Structure\n",
    "1. Data Loading and Basic Statistics\n",
    "2. Class Distribution Analysis\n",
    "3. Magnification Analysis\n",
    "4. Patient-wise Analysis\n",
    "5. Image Quality Assessment\n",
    "6. Visual Analysis\n",
    "7. Data Imbalance Analysis\n",
    "8. Recommendations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m glob\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration\n",
    "DATASET_ROOT = \"../data/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"ğŸ“Š Starting Comprehensive EDA for Breast Cancer Detection\")\n",
    "print(f\"ğŸ“ Dataset Path: {DATASET_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Metadata Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET_ROOT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metadata_df\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Create metadata\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m metadata \u001b[38;5;241m=\u001b[39m create_comprehensive_metadata(\u001b[43mDATASET_ROOT\u001b[49m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Created metadata for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(metadata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“‹ Columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(metadata\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATASET_ROOT' is not defined"
     ]
    }
   ],
   "source": [
    "def create_comprehensive_metadata(dataset_root):\n",
    "    \"\"\"\n",
    "    Create comprehensive metadata from BreakHis dataset\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dataset_root):\n",
    "        raise FileNotFoundError(f\"Dataset path not found: {dataset_root}\")\n",
    "    \n",
    "    # Get all image paths\n",
    "    image_paths = glob(os.path.join(dataset_root, \"*\", \"*\", \"*\", \"*\", \"*\", \"*.png\"))\n",
    "    print(f\"ğŸ” Found {len(image_paths)} images\")\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for path in image_paths:\n",
    "        parts = path.split(os.sep)\n",
    "        try:\n",
    "            # Extract metadata from path structure\n",
    "            label_type = parts[-6]         # 'malignant' or 'benign'\n",
    "            subclass = parts[-4]           # e.g. 'ductal_carcinoma'\n",
    "            magnification = parts[-2]      # e.g. '100X'\n",
    "            filename = os.path.basename(path)\n",
    "            \n",
    "            # Extract patient ID from filename\n",
    "            # Format: SOB_B_A-14-22549AB-40-001.png\n",
    "            filename_parts = filename.split('-')\n",
    "            if len(filename_parts) >= 3:\n",
    "                patient_id = filename_parts[2]\n",
    "            else:\n",
    "                patient_id = \"unknown\"\n",
    "            \n",
    "            # Extract slide number\n",
    "            slide_num = filename.split('-')[-1].replace('.png', '') if '-' in filename else \"001\"\n",
    "            \n",
    "            data.append({\n",
    "                \"path\": path,\n",
    "                \"filename\": filename,\n",
    "                \"label_type\": label_type,\n",
    "                \"subclass\": subclass,\n",
    "                \"magnification\": magnification,\n",
    "                \"patient_id\": patient_id,\n",
    "                \"slide_number\": slide_num\n",
    "            })\n",
    "            \n",
    "        except IndexError as e:\n",
    "            print(f\"âš ï¸ Skipping malformed path: {path}\")\n",
    "            continue\n",
    "    \n",
    "    metadata_df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add derived features\n",
    "    metadata_df['magnification_numeric'] = metadata_df['magnification'].str.replace('X', '').astype(int)\n",
    "    metadata_df['is_malignant'] = (metadata_df['label_type'] == 'malignant').astype(int)\n",
    "    \n",
    "    return metadata_df\n",
    "\n",
    "# Create metadata\n",
    "metadata = create_comprehensive_metadata(DATASET_ROOT)\n",
    "print(f\"âœ… Created metadata for {len(metadata)} images\")\n",
    "print(f\"ğŸ“‹ Columns: {list(metadata.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"ğŸ“Š DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Images: {len(metadata):,}\")\n",
    "print(f\"Unique Patients: {metadata['patient_id'].nunique():,}\")\n",
    "print(f\"Unique Subclasses: {metadata['subclass'].nunique()}\")\n",
    "print(f\"Magnification Levels: {sorted(metadata['magnification'].unique())}\")\n",
    "print(f\"Label Types: {metadata['label_type'].unique()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nğŸ“‹ Sample Data:\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall class distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Benign vs Malignant\n",
    "label_counts = metadata['label_type'].value_counts()\n",
    "axes[0, 0].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('Benign vs Malignant Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Subclass distribution\n",
    "subclass_counts = metadata['subclass'].value_counts()\n",
    "axes[0, 1].barh(range(len(subclass_counts)), subclass_counts.values)\n",
    "axes[0, 1].set_yticks(range(len(subclass_counts)))\n",
    "axes[0, 1].set_yticklabels([label.replace('_', ' ').title() for label in subclass_counts.index])\n",
    "axes[0, 1].set_xlabel('Number of Images')\n",
    "axes[0, 1].set_title('Subclass Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(subclass_counts.values):\n",
    "    axes[0, 1].text(v + 50, i, str(v), va='center', fontweight='bold')\n",
    "\n",
    "# 3. Magnification distribution\n",
    "mag_counts = metadata['magnification'].value_counts().sort_index()\n",
    "axes[1, 0].bar(mag_counts.index, mag_counts.values, color='skyblue', edgecolor='navy')\n",
    "axes[1, 0].set_xlabel('Magnification Level')\n",
    "axes[1, 0].set_ylabel('Number of Images')\n",
    "axes[1, 0].set_title('Magnification Level Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(mag_counts.values):\n",
    "    axes[1, 0].text(i, v + 30, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 4. Images per patient distribution\n",
    "patient_counts = metadata['patient_id'].value_counts()\n",
    "axes[1, 1].hist(patient_counts.values, bins=20, color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Images per Patient')\n",
    "axes[1, 1].set_ylabel('Number of Patients')\n",
    "axes[1, 1].set_title('Images per Patient Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axvline(patient_counts.mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {patient_counts.mean():.1f}')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\nğŸ“Š DETAILED CLASS STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "for label_type in metadata['label_type'].unique():\n",
    "    subset = metadata[metadata['label_type'] == label_type]\n",
    "    print(f\"\\n{label_type.upper()}:\")\n",
    "    print(f\"  Total Images: {len(subset):,}\")\n",
    "    print(f\"  Unique Patients: {subset['patient_id'].nunique()}\")\n",
    "    print(f\"  Subclasses: {subset['subclass'].nunique()}\")\n",
    "    print(f\"  Subclass breakdown:\")\n",
    "    for subclass, count in subset['subclass'].value_counts().items():\n",
    "        print(f\"    - {subclass.replace('_', ' ').title()}: {count:,} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-tabulation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross-tabulation matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# 1. Subclass vs Magnification\n",
    "crosstab_mag = pd.crosstab(metadata['subclass'], metadata['magnification'])\n",
    "sns.heatmap(crosstab_mag, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Subclass vs Magnification Cross-tabulation', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Subclass')\n",
    "axes[0].set_xlabel('Magnification')\n",
    "\n",
    "# Format y-axis labels\n",
    "axes[0].set_yticklabels([label.get_text().replace('_', ' ').title() for label in axes[0].get_yticklabels()], \n",
    "                       rotation=0)\n",
    "\n",
    "# 2. Label Type vs Magnification\n",
    "crosstab_label = pd.crosstab(metadata['label_type'], metadata['magnification'])\n",
    "sns.heatmap(crosstab_label, annot=True, fmt='d', cmap='Reds', ax=axes[1])\n",
    "axes[1].set_title('Label Type vs Magnification Cross-tabulation', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Label Type')\n",
    "axes[1].set_xlabel('Magnification')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print cross-tabulation statistics\n",
    "print(\"\\nğŸ“Š CROSS-TABULATION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nSubclass vs Magnification:\")\n",
    "print(crosstab_mag)\n",
    "print(\"\\nLabel Type vs Magnification:\")\n",
    "print(crosstab_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Patient-wise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient-wise analysis\n",
    "patient_analysis = metadata.groupby('patient_id').agg({\n",
    "    'path': 'count',\n",
    "    'label_type': lambda x: x.iloc[0],  # Assuming all images from same patient have same label\n",
    "    'subclass': lambda x: x.iloc[0],\n",
    "    'magnification': lambda x: list(x.unique())\n",
    "}).rename(columns={'path': 'image_count'})\n",
    "\n",
    "patient_analysis['magnification_count'] = patient_analysis['magnification'].apply(len)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Patient distribution by label type\n",
    "patient_label_counts = patient_analysis['label_type'].value_counts()\n",
    "axes[0, 0].pie(patient_label_counts.values, labels=patient_label_counts.index, \n",
    "               autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('Patient Distribution: Benign vs Malignant', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Images per patient by label type\n",
    "benign_patients = patient_analysis[patient_analysis['label_type'] == 'benign']['image_count']\n",
    "malignant_patients = patient_analysis[patient_analysis['label_type'] == 'malignant']['image_count']\n",
    "\n",
    "axes[0, 1].hist([benign_patients, malignant_patients], bins=15, alpha=0.7, \n",
    "                label=['Benign', 'Malignant'], color=['green', 'red'])\n",
    "axes[0, 1].set_xlabel('Images per Patient')\n",
    "axes[0, 1].set_ylabel('Number of Patients')\n",
    "axes[0, 1].set_title('Images per Patient by Label Type', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Magnification coverage per patient\n",
    "mag_coverage = patient_analysis['magnification_count'].value_counts().sort_index()\n",
    "axes[1, 0].bar(mag_coverage.index, mag_coverage.values, color='orange', edgecolor='darkorange')\n",
    "axes[1, 0].set_xlabel('Number of Different Magnifications')\n",
    "axes[1, 0].set_ylabel('Number of Patients')\n",
    "axes[1, 0].set_title('Magnification Coverage per Patient', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(mag_coverage.values):\n",
    "    axes[1, 0].text(mag_coverage.index[i], v + 1, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 4. Patient distribution by subclass\n",
    "patient_subclass = patient_analysis['subclass'].value_counts()\n",
    "axes[1, 1].barh(range(len(patient_subclass)), patient_subclass.values)\n",
    "axes[1, 1].set_yticks(range(len(patient_subclass)))\n",
    "axes[1, 1].set_yticklabels([label.replace('_', ' ').title() for label in patient_subclass.index])\n",
    "axes[1, 1].set_xlabel('Number of Patients')\n",
    "axes[1, 1].set_title('Patient Distribution by Subclass', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(patient_subclass.values):\n",
    "    axes[1, 1].text(v + 0.5, i, str(v), va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print patient statistics\n",
    "print(\"\\nğŸ‘¥ PATIENT-WISE STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Unique Patients: {len(patient_analysis)}\")\n",
    "print(f\"Benign Patients: {len(patient_analysis[patient_analysis['label_type'] == 'benign'])}\")\n",
    "print(f\"Malignant Patients: {len(patient_analysis[patient_analysis['label_type'] == 'malignant'])}\")\n",
    "print(f\"\\nImages per Patient Statistics:\")\n",
    "print(f\"  Mean: {patient_analysis['image_count'].mean():.2f}\")\n",
    "print(f\"  Median: {patient_analysis['image_count'].median():.2f}\")\n",
    "print(f\"  Min: {patient_analysis['image_count'].min()}\")\n",
    "print(f\"  Max: {patient_analysis['image_count'].max()}\")\n",
    "print(f\"  Std: {patient_analysis['image_count'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Image Quality and Properties Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(metadata_sample, sample_size=100):\n",
    "    \"\"\"\n",
    "    Analyze image properties from a sample of images\n",
    "    \"\"\"\n",
    "    # Sample images for analysis (to avoid processing all images)\n",
    "    sample_metadata = metadata_sample.sample(n=min(sample_size, len(metadata_sample)), \n",
    "                                            random_state=RANDOM_STATE)\n",
    "    \n",
    "    image_properties = []\n",
    "    \n",
    "    print(f\"ğŸ” Analyzing {len(sample_metadata)} sample images...\")\n",
    "    \n",
    "    for idx, row in sample_metadata.iterrows():\n",
    "        try:\n",
    "            # Load image\n",
    "            img = Image.open(row['path'])\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Calculate properties\n",
    "            properties = {\n",
    "                'width': img.width,\n",
    "                'height': img.height,\n",
    "                'channels': len(img_array.shape) if len(img_array.shape) == 2 else img_array.shape[2],\n",
    "                'file_size_kb': os.path.getsize(row['path']) / 1024,\n",
    "                'mean_intensity': np.mean(img_array),\n",
    "                'std_intensity': np.std(img_array),\n",
    "                'min_intensity': np.min(img_array),\n",
    "                'max_intensity': np.max(img_array),\n",
    "                'subclass': row['subclass'],\n",
    "                'magnification': row['magnification'],\n",
    "                'label_type': row['label_type']\n",
    "            }\n",
    "            \n",
    "            image_properties.append(properties)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing {row['path']}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(image_properties)\n",
    "\n",
    "# Analyze image properties\n",
    "image_props = analyze_image_properties(metadata, sample_size=200)\n",
    "print(f\"âœ… Analyzed {len(image_props)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize image properties\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Image dimensions\n",
    "axes[0, 0].scatter(image_props['width'], image_props['height'], alpha=0.6, c='blue')\n",
    "axes[0, 0].set_xlabel('Width (pixels)')\n",
    "axes[0, 0].set_ylabel('Height (pixels)')\n",
    "axes[0, 0].set_title('Image Dimensions Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. File size distribution\n",
    "axes[0, 1].hist(image_props['file_size_kb'], bins=20, color='green', alpha=0.7, edgecolor='darkgreen')\n",
    "axes[0, 1].set_xlabel('File Size (KB)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('File Size Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axvline(image_props['file_size_kb'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {image_props[\"file_size_kb\"].mean():.1f} KB')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Mean intensity by label type\n",
    "sns.boxplot(data=image_props, x='label_type', y='mean_intensity', ax=axes[0, 2])\n",
    "axes[0, 2].set_title('Mean Intensity by Label Type', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].set_ylabel('Mean Intensity')\n",
    "\n",
    "# 4. Mean intensity by magnification\n",
    "sns.boxplot(data=image_props, x='magnification', y='mean_intensity', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Mean Intensity by Magnification', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Mean Intensity')\n",
    "\n",
    "# 5. Standard deviation of intensity\n",
    "axes[1, 1].hist(image_props['std_intensity'], bins=20, color='orange', alpha=0.7, edgecolor='darkorange')\n",
    "axes[1, 1].set_xlabel('Standard Deviation of Intensity')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Intensity Variation Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 6. File size by magnification\n",
    "sns.boxplot(data=image_props, x='magnification', y='file_size_kb', ax=axes[1, 2])\n",
    "axes[1, 2].set_title('File Size by Magnification', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].set_ylabel('File Size (KB)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print image property statistics\n",
    "print(\"\\nğŸ–¼ï¸ IMAGE PROPERTY STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Image Dimensions:\")\n",
    "print(f\"  Width - Mean: {image_props['width'].mean():.0f}, Std: {image_props['width'].std():.0f}\")\n",
    "print(f\"  Height - Mean: {image_props['height'].mean():.0f}, Std: {image_props['height'].std():.0f}\")\n",
    "print(f\"\\nFile Size:\")\n",
    "print(f\"  Mean: {image_props['file_size_kb'].mean():.2f} KB\")\n",
    "print(f\"  Range: {image_props['file_size_kb'].min():.2f} - {image_props['file_size_kb'].max():.2f} KB\")\n",
    "print(f\"\\nIntensity Statistics:\")\n",
    "print(f\"  Mean Intensity: {image_props['mean_intensity'].mean():.2f} Â± {image_props['mean_intensity'].std():.2f}\")\n",
    "print(f\"  Intensity Range: {image_props['min_intensity'].min()} - {image_props['max_intensity'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visual Sample Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(metadata, samples_per_class=2, magnification='100X'):\n",
    "    \"\"\"\n",
    "    Display sample images from each subclass\n",
    "    \"\"\"\n",
    "    # Filter by magnification for consistency\n",
    "    mag_data = metadata[metadata['magnification'] == magnification]\n",
    "    \n",
    "    # Get unique subclasses\n",
    "    subclasses = mag_data['subclass'].unique()\n",
    "    \n",
    "    # Calculate grid size\n",
    "    n_classes = len(subclasses)\n",
    "    n_cols = samples_per_class\n",
    "    n_rows = n_classes\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))\n",
    "    \n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if n_cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i, subclass in enumerate(subclasses):\n",
    "        # Get samples for this subclass\n",
    "        class_data = mag_data[mag_data['subclass'] == subclass]\n",
    "        samples = class_data.sample(n=min(samples_per_class, len(class_data)), \n",
    "                                   random_state=RANDOM_STATE)\n",
    "        \n",
    "        for j, (_, row) in enumerate(samples.iterrows()):\n",
    "            if j >= n_cols:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                # Load and display image\n",
    "                img = Image.open(row['path'])\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].axis('off')\n",
    "                \n",
    "                # Set title\n",
    "                title = f\"{subclass.replace('_', ' ').title()}\\n{row['label_type'].title()}\"\n",
    "                axes[i, j].set_title(title, fontsize=10, fontweight='bold')\n",
    "                \n",
    "            except Exception as e:\n",
    "                axes[i, j].text(0.5, 0.5, f'Error loading\\n{row[\"filename\"]}', \n",
    "                               ha='center', va='center', transform=axes[i, j].transAxes)\n",
    "                axes[i, j].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Sample Images from Each Subclass (Magnification: {magnification})', \n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images\n",
    "display_sample_images(metadata, samples_per_class=3, magnification='100X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_imbalance_metrics(metadata):\n",
    "    \"\"\"\n",
    "    Calculate various imbalance metrics\n",
    "    \"\"\"\n",
    "    # Class distribution\n",
    "    class_counts = metadata['subclass'].value_counts()\n",
    "    \n",
    "    # Calculate imbalance ratio\n",
    "    max_class = class_counts.max()\n",
    "    min_class = class_counts.min()\n",
    "    imbalance_ratio = max_class / min_class\n",
    "    \n",
    "    # Calculate class weights (inverse frequency)\n",
    "    total_samples = len(metadata)\n",
    "    n_classes = len(class_counts)\n",
    "    class_weights = {}\n",
    "    \n",
    "    for class_name, count in class_counts.items():\n",
    "        weight = total_samples / (n_classes * count)\n",
    "        class_weights[class_name] = weight\n",
    "    \n",
    "    return {\n",
    "        'class_counts': class_counts,\n",
    "        'imbalance_ratio': imbalance_ratio,\n",
    "        'class_weights': class_weights,\n",
    "        'total_samples': total_samples,\n",
    "        'n_classes': n_classes\n",
    "    }\n",
    "\n",
    "# Calculate imbalance metrics\n",
    "imbalance_metrics = calculate_imbalance_metrics(metadata)\n",
    "\n",
    "# Visualize imbalance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. Class distribution (sorted)\n",
    "class_counts = imbalance_metrics['class_counts']\n",
    "axes[0].bar(range(len(class_counts)), class_counts.values, color='lightblue', edgecolor='navy')\n",
    "axes[0].set_xticks(range(len(class_counts)))\n",
    "axes[0].set_xticklabels([label.replace('_', '\\n').title() for label in class_counts.index], \n",
    "                       rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Number of Images')\n",
    "axes[0].set_title('Class Distribution (Sorted by Count)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0].text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Class weights\n",
    "class_weights = imbalance_metrics['class_weights']\n",
    "weights_sorted = dict(sorted(class_weights.items(), key=lambda x: x[1], reverse=True))\n",
    "axes[1].bar(range(len(weights_sorted)), list(weights_sorted.values()), \n",
    "           color='lightcoral', edgecolor='darkred')\n",
    "axes[1].set_xticks(range(len(weights_sorted)))\n",
    "axes[1].set_xticklabels([label.replace('_', '\\n').title() for label in weights_sorted.keys()], \n",
    "                       rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Class Weight')\n",
    "axes[1].set_title('Calculated Class Weights', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Imbalance visualization\n",
    "normalized_counts = class_counts / class_counts.sum() * 100\n",
    "axes[2].pie(normalized_counts.values, labels=[label.replace('_', ' ').title() for label in normalized_counts.index], \n",
    "           autopct='%1.1f%%', startangle=90)\n",
    "axes[2].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print imbalance statistics\n",
    "print(\"\\nâš–ï¸ DATA IMBALANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Imbalance Ratio (Max/Min): {imbalance_metrics['imbalance_ratio']:.2f}\")\n",
    "print(f\"Most Common Class: {class_counts.index[0]} ({class_counts.iloc[0]:,} images)\")\n",
    "print(f\"Least Common Class: {class_counts.index[-1]} ({class_counts.iloc[-1]:,} images)\")\n",
    "print(f\"\\nClass Distribution:\")\n",
    "for class_name, count in class_counts.items():\n",
    "    percentage = (count / imbalance_metrics['total_samples']) * 100\n",
    "    print(f\"  {class_name.replace('_', ' ').title()}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nRecommended Class Weights:\")\n",
    "for class_name, weight in sorted(class_weights.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {class_name.replace('_', ' ').title()}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train/Validation/Test Split Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_patient_wise_splits(metadata, test_size=0.15, val_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Create patient-wise stratified splits to avoid data leakage\n",
    "    \"\"\"\n",
    "    # Get unique patients with their labels\n",
    "    patient_labels = metadata.groupby('patient_id')['subclass'].first().reset_index()\n",
    "    \n",
    "    # First split: train+val vs test\n",
    "    train_val_patients, test_patients = train_test_split(\n",
    "        patient_labels, test_size=test_size, \n",
    "        stratify=patient_labels['subclass'], random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Second split: train vs val\n",
    "    val_size_adjusted = val_size / (1 - test_size)\n",
    "    train_patients, val_patients = train_test_split(\n",
    "        train_val_patients, test_size=val_size_adjusted,\n",
    "        stratify=train_val_patients['subclass'], random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Map back to full metadata\n",
    "    train_data = metadata[metadata['patient_id'].isin(train_patients['patient_id'])]\n",
    "    val_data = metadata[metadata['patient_id'].isin(val_patients['patient_id'])]\n",
    "    test_data = metadata[metadata['patient_id'].isin(test_patients['patient_id'])]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Create splits\n",
    "train_data, val_data, test_data = create_patient_wise_splits(metadata)\n",
    "\n",
    "# Analyze splits\n",
    "splits_info = {\n",
    "    'Train': train_data,\n",
    "    'Validation': val_data,\n",
    "    'Test': test_data\n",
    "}\n",
    "\n",
    "# Visualize splits\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Split sizes\n",
    "split_sizes = [len(data) for data in splits_info.values()]\n",
    "split_names = list(splits_info.keys())\n",
    "axes[0, 0].pie(split_sizes, labels=split_names, autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('Dataset Split Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Class distribution across splits\n",
    "split_class_data = []\n",
    "for split_name, data in splits_info.items():\n",
    "    for subclass in data['subclass'].unique():\n",
    "        count = len(data[data['subclass'] == subclass])\n",
    "        split_class_data.append({\n",
    "            'Split': split_name,\n",
    "            'Subclass': subclass.replace('_', ' ').title(),\n",
    "            'Count': count\n",
    "        })\n",
    "\n",
    "split_class_df = pd.DataFrame(split_class_data)\n",
    "pivot_data = split_class_df.pivot(index='Subclass', columns='Split', values='Count')\n",
    "pivot_data.plot(kind='bar', ax=axes[0, 1], width=0.8)\n",
    "axes[0, 1].set_title('Class Distribution Across Splits', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Subclass')\n",
    "axes[0, 1].set_ylabel('Number of Images')\n",
    "axes[0, 1].legend(title='Split')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Patient distribution across splits\n",
    "patient_splits = []\n",
    "for split_name, data in splits_info.items():\n",
    "    n_patients = data['patient_id'].nunique()\n",
    "    patient_splits.append(n_patients)\n",
    "\n",
    "axes[1, 0].bar(split_names, patient_splits, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[1, 0].set_ylabel('Number of Patients')\n",
    "axes[1, 0].set_title('Patient Distribution Across Splits', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(patient_splits):\n",
    "    axes[1, 0].text(i, v + 1, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 4. Magnification distribution across splits\n",
    "mag_split_data = []\n",
    "for split_name, data in splits_info.items():\n",
    "    for mag in data['magnification'].unique():\n",
    "        count = len(data[data['magnification'] == mag])\n",
    "        mag_split_data.append({\n",
    "            'Split': split_name,\n",
    "            'Magnification': mag,\n",
    "            'Count': count\n",
    "        })\n",
    "\n",
    "mag_split_df = pd.DataFrame(mag_split_data)\n",
    "mag_pivot = mag_split_df.pivot(index='Magnification', columns='Split', values='Count')\n",
    "mag_pivot.plot(kind='bar', ax=axes[1, 1], width=0.8)\n",
    "axes[1, 1].set_title('Magnification Distribution Across Splits', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Magnification')\n",
    "axes[1, 1].set_ylabel('Number of Images')\n",
    "axes[1, 1].legend(title='Split')\n",
    "axes[1, 1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print split statistics\n",
    "print(\"\\nğŸ“Š TRAIN/VALIDATION/TEST SPLIT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "for split_name, data in splits_info.items():\n",
    "    print(f\"\\n{split_name.upper()} SET:\")\n",
    "    print(f\"  Images: {len(data):,}\")\n",
    "    print(f\"  Patients: {data['patient_id'].nunique()}\")\n",
    "    print(f\"  Percentage: {(len(data)/len(metadata)*100):.1f}%\")\n",
    "    print(f\"  Class distribution:\")\n",
    "    for subclass, count in data['subclass'].value_counts().items():\n",
    "        percentage = (count / len(data)) * 100\n",
    "        print(f\"    - {subclass.replace('_', ' ').title()}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recommendations and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary and recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“‹ COMPREHENSIVE EDA SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ” DATASET OVERVIEW:\")\n",
    "print(f\"  â€¢ Total Images: {len(metadata):,}\")\n",
    "print(f\"  â€¢ Unique Patients: {metadata['patient_id'].nunique()}\")\n",
    "print(f\"  â€¢ Classes: {metadata['subclass'].nunique()} subclasses (4 benign + 4 malignant)\")\n",
    "print(f\"  â€¢ Magnifications: {len(metadata['magnification'].unique())} levels (40X, 100X, 200X, 400X)\")\n",
    "\n",
    "print(\"\\nâš–ï¸ DATA IMBALANCE INSIGHTS:\")\n",
    "print(f\"  â€¢ Imbalance Ratio: {imbalance_metrics['imbalance_ratio']:.2f}:1\")\n",
    "print(f\"  â€¢ Most Common: {class_counts.index[0].replace('_', ' ').title()} ({class_counts.iloc[0]:,} images)\")\n",
    "print(f\"  â€¢ Least Common: {class_counts.index[-1].replace('_', ' ').title()} ({class_counts.iloc[-1]:,} images)\")\n",
    "print(f\"  â€¢ Recommendation: Use weighted sampling or class weights during training\")\n",
    "\n",
    "print(\"\\nğŸ‘¥ PATIENT-WISE ANALYSIS:\")\n",
    "print(f\"  â€¢ Images per Patient: {patient_analysis['image_count'].mean():.1f} Â± {patient_analysis['image_count'].std():.1f}\")\n",
    "print(f\"  â€¢ Patient Distribution: {len(patient_analysis[patient_analysis['label_type'] == 'benign'])} benign, {len(patient_analysis[patient_analysis['label_type'] == 'malignant'])} malignant\")\n",
    "print(f\"  â€¢ Recommendation: Use patient-wise splits to avoid data leakage\")\n",
    "\n",
    "print(\"\\nğŸ–¼ï¸ IMAGE PROPERTIES:\")\n",
    "if len(image_props) > 0:\n",
    "    print(f\"  â€¢ Average Dimensions: {image_props['width'].mean():.0f} x {image_props['height'].mean():.0f} pixels\")\n",
    "    print(f\"  â€¢ Average File Size: {image_props['file_size_kb'].mean():.1f} KB\")\n",
    "    print(f\"  â€¢ Intensity Range: {image_props['min_intensity'].min()} - {image_props['max_intensity'].max()}\")\n",
    "    print(f\"  â€¢ Recommendation: Resize to 224x224 for EfficientNet, normalize with ImageNet stats\")\n",
    "\n",
    "print(\"\\nğŸ“Š TRAINING RECOMMENDATIONS:\")\n",
    "print(\"  1. DATA PREPROCESSING:\")\n",
    "print(\"     â€¢ Resize images to 224x224 pixels\")\n",
    "print(\"     â€¢ Normalize with ImageNet statistics (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\")\n",
    "print(\"     â€¢ Apply data augmentation (rotation, flip, color jitter)\")\n",
    "\n",
    "print(\"\\n  2. DATA SPLITTING:\")\n",
    "print(\"     â€¢ Use patient-wise stratified splits (70% train, 15% val, 15% test)\")\n",
    "print(\"     â€¢ Ensure no patient appears in multiple splits\")\n",
    "print(\"     â€¢ Maintain class distribution across splits\")\n",
    "\n",
    "print(\"\\n  3. CLASS IMBALANCE HANDLING:\")\n",
    "print(\"     â€¢ Use WeightedRandomSampler during training\")\n",
    "print(\"     â€¢ Apply class weights in loss function\")\n",
    "print(\"     â€¢ Consider focal loss for severe imbalance\")\n",
    "\n",
    "print(\"\\n  4. MODEL ARCHITECTURE:\")\n",
    "print(\"     â€¢ Start with EfficientNetB0 (good balance of accuracy and efficiency)\")\n",
    "print(\"     â€¢ Use transfer learning with ImageNet pretrained weights\")\n",
    "print(\"     â€¢ Fine-tune the entire network with lower learning rate\")\n",
    "\n",
    "print(\"\\n  5. TRAINING STRATEGY:\")\n",
    "print(\"     â€¢ Batch size: 32-64 (depending on GPU memory)\")\n",
    "print(\"     â€¢ Learning rate: 1e-4 with cosine annealing\")\n",
    "print(\"     â€¢ Early stopping based on validation accuracy\")\n",
    "print(\"     â€¢ Save best model based on validation performance\")\n",
    "\n",
    "print(\"\\n  6. EVALUATION METRICS:\")\n",
    "print(\"     â€¢ Accuracy, Precision, Recall, F1-score (per class and macro/micro avg)\")\n",
    "print(\"     â€¢ Confusion matrix analysis\")\n",
    "print(\"     â€¢ ROC-AUC curves for each class\")\n",
    "print(\"     â€¢ Per-magnification performance analysis\")\n",
    "\n",
    "print(\"\\nğŸš€ NEXT STEPS:\")\n",
    "print(\"  1. Implement the recommended preprocessing pipeline\")\n",
    "print(\"  2. Create patient-wise stratified splits\")\n",
    "print(\"  3. Train EfficientNetB0 baseline with class balancing\")\n",
    "print(\"  4. Evaluate performance and analyze failure cases\")\n",
    "print(\"  5. Consider advanced techniques (ensemble, multi-scale, etc.)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… EDA COMPLETED - Ready for model development!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key results for later use\n",
    "import pickle\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('../results/eda', exist_ok=True)\n",
    "\n",
    "# Save metadata\n",
    "metadata.to_csv('../results/eda/dataset_metadata.csv', index=False)\n",
    "print(\"âœ… Saved dataset metadata to ../results/eda/dataset_metadata.csv\")\n",
    "\n",
    "# Save splits\n",
    "train_data.to_csv('../results/eda/train_split.csv', index=False)\n",
    "val_data.to_csv('../results/eda/val_split.csv', index=False)\n",
    "test_data.to_csv('../results/eda/test_split.csv', index=False)\n",
    "print(\"âœ… Saved train/val/test splits to ../results/eda/\")\n",
    "\n",
    "# Save class mappings and weights\n",
    "class_info = {\n",
    "    'class_counts': dict(class_counts),\n",
    "    'class_weights': class_weights,\n",
    "    'imbalance_ratio': imbalance_metrics['imbalance_ratio']\n",
    "}\n",
    "\n",
    "with open('../results/eda/class_info.pkl', 'wb') as f:\n",
    "    pickle.dump(class_info, f)\n",
    "print(\"âœ… Saved class information to ../results/eda/class_info.pkl\")\n",
    "\n",
    "# Save image properties (if analyzed)\n",
    "if len(image_props) > 0:\n",
    "    image_props.to_csv('../results/eda/image_properties.csv', index=False)\n",
    "    print(\"âœ… Saved image properties to ../results/eda/image_properties.csv\")\n",
    "\n",
    "print(\"\\nğŸ‰ EDA results exported successfully!\")\n",
    "print(\"ğŸ“ Check the ../results/eda/ directory for all saved files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "7 aug (Thesis)",
   "language": "python",
   "name": "thesis_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
